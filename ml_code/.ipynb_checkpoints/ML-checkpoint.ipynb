{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adf1ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fd1131d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame: (5257, 6)\n",
      "Validation DataFrame: (657, 6)\n",
      "Test DataFrame: (658, 6)\n",
      "\n",
      "Train DataFrame 정보:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>normalized_score</th>\n",
       "      <th>summary_ratio_score</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일을 하면서 가장 어려울 것으로 예상하고 계시는 것은 무엇인가요 또한 그런 어려운 ...</td>\n",
       "      <td>가장 어려울 것으로 예상되는 점은 역시나 사람입니다. 사람만큼 어려운 게 있을까 싶...</td>\n",
       "      <td>0.4779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>커뮤니케이션을 잘 할 수 있는 나만의 스킬이 있다면 한번 소개해 주실 수 있으십니까...</td>\n",
       "      <td>커뮤니케이션 스킬 중에 하나는 타인의 이야기를 잘 듣는 경청의 자세가 우선되어야 한...</td>\n",
       "      <td>0.7518</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>협업을 하다 보면 여러 동료들과 소통을 해야 되는데 비아이티 동료와 효과적으로 의사...</td>\n",
       "      <td>네 대화 주제를 어느 방향으로 이끌어가느냐에 달려 있다고 생각합니다. 우선 아이티 ...</td>\n",
       "      <td>0.4949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이제까지 살면서 새로운 환경에서 아예 몰랐던 일을 해 본 경험이 있다면 경험에 대해...</td>\n",
       "      <td>전혀 몰랐던 일을 맡아서 했던 경험 있기는 있던 것 같습니다. 뭐 사진을 찍을 때도...</td>\n",
       "      <td>0.6406</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>만약 함께 일하는 동료 가운데 이직을 생각하는 동료를 만나게 된다면 뭐라고 말씀하시...</td>\n",
       "      <td>제가 회사 생활을 하면서 제 동료가 만약에 이직을 원한다면 일단은 어떤 결론을 내기...</td>\n",
       "      <td>0.4295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  일을 하면서 가장 어려울 것으로 예상하고 계시는 것은 무엇인가요 또한 그런 어려운 ...   \n",
       "1  커뮤니케이션을 잘 할 수 있는 나만의 스킬이 있다면 한번 소개해 주실 수 있으십니까...   \n",
       "2  협업을 하다 보면 여러 동료들과 소통을 해야 되는데 비아이티 동료와 효과적으로 의사...   \n",
       "3  이제까지 살면서 새로운 환경에서 아예 몰랐던 일을 해 본 경험이 있다면 경험에 대해...   \n",
       "4  만약 함께 일하는 동료 가운데 이직을 생각하는 동료를 만나게 된다면 뭐라고 말씀하시...   \n",
       "\n",
       "                                              answer  normalized_score  \\\n",
       "0  가장 어려울 것으로 예상되는 점은 역시나 사람입니다. 사람만큼 어려운 게 있을까 싶...            0.4779   \n",
       "1  커뮤니케이션 스킬 중에 하나는 타인의 이야기를 잘 듣는 경청의 자세가 우선되어야 한...            0.7518   \n",
       "2  네 대화 주제를 어느 방향으로 이끌어가느냐에 달려 있다고 생각합니다. 우선 아이티 ...            0.4949   \n",
       "3  전혀 몰랐던 일을 맡아서 했던 경험 있기는 있던 것 같습니다. 뭐 사진을 찍을 때도...            0.6406   \n",
       "4  제가 회사 생활을 하면서 제 동료가 만약에 이직을 원한다면 일단은 어떤 결론을 내기...            0.4295   \n",
       "\n",
       "   summary_ratio_score  emotion   score  \n",
       "0                  1.0      0.0  0.4926  \n",
       "1                  1.0      0.0  0.5839  \n",
       "2                  1.0      0.0  0.4983  \n",
       "3                  1.0      0.0  0.5469  \n",
       "4                  1.0      0.0  0.4765  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JSON 파일 읽어오기\n",
    "def load_json_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def json_to_dataframe(json_data):\n",
    "    \"\"\"JSON 데이터를 DataFrame으로 변환\"\"\"\n",
    "    df_data = []\n",
    "    for item in json_data:\n",
    "        row = {\n",
    "            'question': item.get('question', ''),\n",
    "            'answer': item.get('answer', ''),\n",
    "            'normalized_score': item.get('normalized_score', 0),\n",
    "            'summary_ratio_score': item.get('summary_ratio_score', 0),\n",
    "            'emotion': item.get('emotion', 0),\n",
    "            'score': item.get('score', 0)\n",
    "        }\n",
    "        df_data.append(row)\n",
    "    return pd.DataFrame(df_data)\n",
    "\n",
    "# 데이터 로드 및 DataFrame 변환\n",
    "train_data_json = load_json_data('new_train_qa_normalized.json')\n",
    "val_data_json = load_json_data('new_val_qa_normalized.json')\n",
    "test_data_json = load_json_data('new_test_qa_normalized.json')\n",
    "\n",
    "df_train_json = json_to_dataframe(train_data_json)\n",
    "df_val_json = json_to_dataframe(val_data_json)\n",
    "df_test_json = json_to_dataframe(test_data_json)\n",
    "\n",
    "print(f\"Train DataFrame: {df_train_json.shape}\")\n",
    "print(f\"Validation DataFrame: {df_val_json.shape}\")\n",
    "print(f\"Test DataFrame: {df_test_json.shape}\")\n",
    "\n",
    "# DataFrame 구조 확인\n",
    "print(\"\\nTrain DataFrame 정보:\")\n",
    "df_train_json.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb25c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# npz 불러오기\n",
    "train = np.load(\"train_set.npz\")\n",
    "X_train = train[\"X\"]\n",
    "y_train = df_train_json[\"score\"]\n",
    "\n",
    "# 컬럼 이름 만들기\n",
    "n_features = X_train.shape[1]\n",
    "feature_columns = [f\"f{i}\" for i in range(n_features)]\n",
    "\n",
    "# DataFrame 생성\n",
    "df_train = pd.DataFrame(X_train, columns=feature_columns)\n",
    "df_train[\"score\"] = y_train*100  # 종속변수 추가\n",
    "\n",
    "val = np.load(\"val_set.npz\")\n",
    "X_val = val[\"X\"]\n",
    "y_val = df_val_json[\"score\"]\n",
    "df_val = pd.DataFrame(X_val, columns=feature_columns)\n",
    "df_val[\"score\"] = y_val*100\n",
    "\n",
    "test = np.load(\"test_set.npz\")\n",
    "X_test = test[\"X\"]\n",
    "y_test = df_test_json[\"score\"]\n",
    "df_test = pd.DataFrame(X_test, columns=feature_columns)\n",
    "df_test[\"score\"] = y_test*100\n",
    "\n",
    "train_data = TabularDataset(df_train)\n",
    "val_data = TabularDataset(df_val)\n",
    "test_data = TabularDataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df0a5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4fbf1df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"automl/\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.10.18\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          16\n",
      "Memory Avail:       15.45 GB / 31.64 GB (48.8%)\n",
      "Disk Space Avail:   258.14 GB / 476.00 GB (54.2%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.10.18\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          16\n",
      "Memory Avail:       15.45 GB / 31.64 GB (48.8%)\n",
      "Disk Space Avail:   258.14 GB / 476.00 GB (54.2%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"c:\\tjrdnjs\\Qkddl\\automl\"\n",
      "Train Data Rows:    5257\n",
      "Train Data Columns: 1536\n",
      "Tuning Data Rows:    657\n",
      "Tuning Data Columns: 1536\n",
      "Label Column:       score\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"c:\\tjrdnjs\\Qkddl\\automl\"\n",
      "Train Data Rows:    5257\n",
      "Train Data Columns: 1536\n",
      "Tuning Data Rows:    657\n",
      "Tuning Data Columns: 1536\n",
      "Label Column:       score\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15772.09 MB\n",
      "\tTrain Data (Original)  Memory Usage: 34.65 MB (0.2% of available memory)\n",
      "\tAvailable Memory:                    15772.09 MB\n",
      "\tTrain Data (Original)  Memory Usage: 34.65 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1536 | ['f0', 'f1', 'f2', 'f3', 'f4', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1536 | ['f0', 'f1', 'f2', 'f3', 'f4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1536 | ['f0', 'f1', 'f2', 'f3', 'f4', ...]\n",
      "\t3.5s = Fit runtime\n",
      "\t1536 features in original data used to generate 1536 features in processed data.\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1536 | ['f0', 'f1', 'f2', 'f3', 'f4', ...]\n",
      "\t3.5s = Fit runtime\n",
      "\t1536 features in original data used to generate 1536 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 34.65 MB (0.2% of available memory)\n",
      "\tTrain Data (Processed) Memory Usage: 34.65 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.87s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Data preprocessing and feature engineering runtime = 3.87s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 596.13s of the 596.13s of remaining time.\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 596.13s of the 596.13s of remaining time.\n",
      "\t-7.577\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "\t-7.577\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 594.56s of the 594.56s of remaining time.\n",
      "Fitting model: KNeighborsDist ... Training model for up to 594.56s of the 594.56s of remaining time.\n",
      "\t-7.5414\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t1.03s\t = Validation runtime\n",
      "\t-7.5414\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t1.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 593.02s of the 593.02s of remaining time.\n",
      "Fitting model: LightGBMXT ... Training model for up to 593.02s of the 593.02s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 6.23123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-6.2287\t = Validation score   (-root_mean_squared_error)\n",
      "\t30.88s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "\t30.88s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 562.03s of the 562.03s of remaining time.\n",
      "Fitting model: LightGBM ... Training model for up to 562.03s of the 562.03s of remaining time.\n",
      "\t-6.3435\t = Validation score   (-root_mean_squared_error)\n",
      "\t36.29s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "\t-6.3435\t = Validation score   (-root_mean_squared_error)\n",
      "\t36.29s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 525.66s of the 525.66s of remaining time.\n",
      "Fitting model: RandomForestMSE ... Training model for up to 525.66s of the 525.66s of remaining time.\n",
      "\t-6.7059\t = Validation score   (-root_mean_squared_error)\n",
      "\t620.61s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "\t-6.7059\t = Validation score   (-root_mean_squared_error)\n",
      "\t620.61s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the -95.45s of remaining time.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the -95.45s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT': 1.0}\n",
      "\t-6.2287\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 695.58s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 23464.2 rows/s (657 batch size)\n",
      "\tEnsemble Weights: {'LightGBMXT': 1.0}\n",
      "\t-6.2287\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 695.58s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 23464.2 rows/s (657 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\tjrdnjs\\Qkddl\\automl\")\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\tjrdnjs\\Qkddl\\automl\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root_mean_squared_error: -6.695962333417998\n",
      "mean_squared_error: -44.835911570552604\n",
      "mean_absolute_error: -4.521185811051481\n",
      "r2: 0.4538397177818283\n",
      "pearsonr: 0.6825826298349335\n",
      "median_absolute_error: -3.1224677276611317\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label='score',\n",
    "    path='automl/',\n",
    "    problem_type='regression',\n",
    "    eval_metric='rmse'  # 💡 평가 지표를 RMSE로 설정\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    tuning_data=val_data,       # 💡 검증 데이터 명시\n",
    "    time_limit=600\n",
    ")\n",
    "\n",
    "# 평가: 여러 지표 다 나옴\n",
    "results = predictor.evaluate(test_data)\n",
    "\n",
    "# 출력\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d81e62a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-6.695962</td>\n",
       "      <td>-6.228672</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.039003</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>30.880543</td>\n",
       "      <td>0.039003</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>30.880543</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-6.695962</td>\n",
       "      <td>-6.228672</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.060009</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>30.896077</td>\n",
       "      <td>0.021006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015533</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-6.808247</td>\n",
       "      <td>-6.343531</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.042011</td>\n",
       "      <td>0.026005</td>\n",
       "      <td>36.285259</td>\n",
       "      <td>0.042011</td>\n",
       "      <td>0.026005</td>\n",
       "      <td>36.285259</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-7.336781</td>\n",
       "      <td>-6.705860</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.344626</td>\n",
       "      <td>0.194681</td>\n",
       "      <td>620.611826</td>\n",
       "      <td>0.344626</td>\n",
       "      <td>0.194681</td>\n",
       "      <td>620.611826</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-8.150046</td>\n",
       "      <td>-7.541428</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.244310</td>\n",
       "      <td>1.029261</td>\n",
       "      <td>0.450217</td>\n",
       "      <td>1.244310</td>\n",
       "      <td>1.029261</td>\n",
       "      <td>0.450217</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-8.179447</td>\n",
       "      <td>-7.577029</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.135977</td>\n",
       "      <td>0.984943</td>\n",
       "      <td>0.516378</td>\n",
       "      <td>1.135977</td>\n",
       "      <td>0.984943</td>\n",
       "      <td>0.516378</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val              eval_metric  \\\n",
       "0           LightGBMXT   -6.695962  -6.228672  root_mean_squared_error   \n",
       "1  WeightedEnsemble_L2   -6.695962  -6.228672  root_mean_squared_error   \n",
       "2             LightGBM   -6.808247  -6.343531  root_mean_squared_error   \n",
       "3      RandomForestMSE   -7.336781  -6.705860  root_mean_squared_error   \n",
       "4       KNeighborsDist   -8.150046  -7.541428  root_mean_squared_error   \n",
       "5       KNeighborsUnif   -8.179447  -7.577029  root_mean_squared_error   \n",
       "\n",
       "   pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  \\\n",
       "0        0.039003       0.028000   30.880543                 0.039003   \n",
       "1        0.060009       0.028000   30.896077                 0.021006   \n",
       "2        0.042011       0.026005   36.285259                 0.042011   \n",
       "3        0.344626       0.194681  620.611826                 0.344626   \n",
       "4        1.244310       1.029261    0.450217                 1.244310   \n",
       "5        1.135977       0.984943    0.516378                 1.135977   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.028000          30.880543            1       True   \n",
       "1                0.000000           0.015533            2       True   \n",
       "2                0.026005          36.285259            1       True   \n",
       "3                0.194681         620.611826            1       True   \n",
       "4                1.029261           0.450217            1       True   \n",
       "5                0.984943           0.516378            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          3  \n",
       "1          6  \n",
       "2          4  \n",
       "3          5  \n",
       "4          2  \n",
       "5          1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습된 모델들의 성능을 확인합니다.\n",
    "leaderboard = predictor.leaderboard(test_data, silent=True)\n",
    "leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b852744d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-6.695962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-6.695962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-6.808247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-7.336781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-8.150046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-8.179447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test\n",
       "0           LightGBMXT   -6.695962\n",
       "1  WeightedEnsemble_L2   -6.695962\n",
       "2             LightGBM   -6.808247\n",
       "3      RandomForestMSE   -7.336781\n",
       "4       KNeighborsDist   -8.150046\n",
       "5       KNeighborsUnif   -8.179447"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리더보드에서 모델명과 테스트 점수만 표시\n",
    "leaderboard_simple = leaderboard[['model', 'score_test']].copy()\n",
    "leaderboard_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c672fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 LightGBMXT 하이퍼파라미터:\n",
      " - learning_rate: 0.05\n",
      " - extra_trees: True\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor.load(\"automl/\")  # 저장된 predictor 불러오기\n",
    "leaderboard = predictor.leaderboard(silent=True)\n",
    "\n",
    "# 모델 이름 확인 (예: LightGBMXT_BAG_L1)\n",
    "model_name = \"LightGBMXT\"\n",
    "\n",
    "# 하이퍼파라미터 조회\n",
    "info = predictor.info()\n",
    "params = info['model_info'][model_name]['hyperparameters']\n",
    "\n",
    "print(f\"📌 {model_name} 하이퍼파라미터:\")\n",
    "for k, v in params.items():\n",
    "    print(f\" - {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61013ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4538397177818283\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score # r2_score 임포트 추가\n",
    "\n",
    "# 모델이 저장된 경로\n",
    "model_path = 'automl/' # \n",
    "\n",
    "# 모델 불러오기\n",
    "predictor = TabularPredictor.load(model_path)\n",
    "\n",
    "# 예측 값 (클래스 값)\n",
    "y_pred = predictor.predict(test_data)\n",
    "\n",
    "overall_r2 = r2_score(test_data['score'], y_pred)\n",
    "print(overall_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edd568c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\AppData\\Local\\miniconda3\\envs\\mo\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>지표</th>\n",
       "      <th>값</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>6.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R² Score</td>\n",
       "      <td>0.454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         지표      값\n",
       "0      RMSE  6.696\n",
       "1  R² Score  0.454"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 예측값 계산 (AutoGluon predictor 썼다면)\n",
    "y_pred = predictor.predict(test_data)\n",
    "\n",
    "# 실제값\n",
    "y_true = test_data['score']  # 또는 y_test\n",
    "\n",
    "# RMSE, R2 계산\n",
    "rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "# 데이터프레임 형태로 보기 좋게 출력\n",
    "df_metrics = pd.DataFrame({\n",
    "    \"지표\": [\"RMSE\", \"R² Score\"],\n",
    "    \"값\": [round(rmse, 3), round(r2, 3)]\n",
    "})\n",
    "\n",
    "import IPython.display as dsp\n",
    "dsp.display(df_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e5a0ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상위 3개 모델 성능 비교:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\AppData\\Local\\miniconda3\\envs\\mo\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\miniconda3\\envs\\mo\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\miniconda3\\envs\\mo\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>모델명</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R² Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>6.6960</td>\n",
       "      <td>0.4538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>6.6960</td>\n",
       "      <td>0.4538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>6.8082</td>\n",
       "      <td>0.4354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   모델명    RMSE  R² Score\n",
       "0  WeightedEnsemble_L2  6.6960    0.4538\n",
       "1           LightGBMXT  6.6960    0.4538\n",
       "2             LightGBM  6.8082    0.4354"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# 상위 3개 모델 이름 가져오기\n",
    "top_3_models = leaderboard['model'].head(3).tolist()\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "results = []\n",
    "\n",
    "for model_name in top_3_models:\n",
    "    # 각 모델로 예측\n",
    "    y_pred = predictor.predict(test_data, model=model_name)\n",
    "    y_true = test_data['score']\n",
    "    \n",
    "    # RMSE, R2 계산\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        '모델명': model_name,\n",
    "        'RMSE': round(rmse, 4),\n",
    "        'R² Score': round(r2, 4)\n",
    "    })\n",
    "\n",
    "# 데이터프레임으로 변환하여 표 형태로 출력\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"상위 3개 모델 성능 비교:\")\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
