{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67cd997c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\final_git\\SKN12-FINAL-5TEAM\n",
      "c:\\final_git\\SKN12-FINAL-5TEAM\\data\\ML\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# 데이터 경로 (os.path.join 사용, 절대 경로)\n",
    "BASE_DIR = os.path.dirname(os.getcwd())  # ml_code 폴더의 상위 폴더로 이동\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data', 'ML')\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "print(BASE_DIR)\n",
    "print(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9a61ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data path: c:\\final_git\\SKN12-FINAL-5TEAM\\data\\채용면접 인터뷰 데이터\\Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# BASE_DIR = os.path.abspath(os.path.dirname(__file__))\n",
    "TRAINING_DATA_PATH = os.path.join(BASE_DIR, 'data', '채용면접 인터뷰 데이터', 'Training')\n",
    "VALIDATION_DATA_PATH = os.path.join(BASE_DIR,'data', '채용면접 인터뷰 데이터', 'Validation')\n",
    "OUTPUT_FILE_PATH = os.path.join(BASE_DIR,'data', 'preprocessed_data.json')\n",
    "\n",
    "print(f\"Training data path: {TRAINING_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c246c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at BM-K/KoSimCSE-roberta and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 전처리 파라미터\n",
    "MIN_SENTENCE_LENGTH = 5  # 이 길이 미만의 문장은 필터링\n",
    "\n",
    "# 제거할 추임새 및 습관어 목록 (정규식으로 구성)\n",
    "# 주의: 단어 경계(\\b)를 사용하여 부분 일치를 방지 (예: '그'가 '그림'에서 삭제되는 것을 방지)\n",
    "FILLER_WORDS_PATTERN = re.compile(\n",
    "    r'\\b(음|네|아|어|그|저|뭐랄까|그러니까|사실|그냥|약간|일단|아무튼|솔직히|어떻게 보면|좀|너무|글쎄요|있잖아요|뭐라고 해야 할까|노력하는 편입니다|잘 모르겠지만)\\b'\n",
    ")\n",
    "\n",
    "# 제거할 불필요한 기호 목록\n",
    "SYMBOL_PATTERN = re.compile(r'[\\\"()[\\\\].,?!...]{2,}') # 2번 이상 반복되는 기호\n",
    "WHITESPACE_PATTERN = re.compile(r'\\s+') # 중복 공백\n",
    "# model = CrossEncoder(\"BM-K/KoSimCSE-roberta\", device='cuda', max_length=512)\n",
    "model = CrossEncoder(\"BM-K/KoSimCSE-roberta\", max_length=512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1244a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_fillers(text):\n",
    "    \"\"\"추임새 및 습관어를 제거합니다.\"\"\"\n",
    "    return FILLER_WORDS_PATTERN.sub('', text).strip()\n",
    "\n",
    "def remove_symbols(text):\n",
    "    \"\"\"불필요한 기호를 제거합니다.\"\"\"\n",
    "    return SYMBOL_PATTERN.sub(' ', text)\n",
    "\n",
    "def normalize_whitespace(text):\n",
    "    \"\"\"중복 공백 및 앞뒤 공백을 정리합니다.\"\"\"\n",
    "    return WHITESPACE_PATTERN.sub(' ', text).strip()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"정의된 파이프라인에 따라 텍스트를 전처리합니다.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # 1. 추임새 및 습관어 제거\n",
    "    text = remove_fillers(text)\n",
    "    # 2. 불필요한 기호 제거\n",
    "    text = remove_symbols(text)\n",
    "    # 3. 공백 정리\n",
    "    text = normalize_whitespace(text)\n",
    "    # 4. (선택) 맞춤법 교정\n",
    "    # text = correct_spelling(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def compute_similarity(question, answer, model):\n",
    "    # CrossEncoder는 쌍으로 넣음\n",
    "    return float(model.predict([(question, answer)])[0])\n",
    "\n",
    "def normalize_score(score, min_score, max_score):\n",
    "    return (score - min_score) / (max_score - min_score)\n",
    "\n",
    "def save_json(data, output_path):\n",
    "    \"\"\"데이터를 JSON 파일로 저장합니다.\"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 감정 expression → 점수 매핑\n",
    "def get_emotion_score(expression):\n",
    "    positive = [\"p-achievement\", \"p-affection\", \"p-gratitude\", \"p-happiness\", \"p-interest\"]\n",
    "    negative = [\"n-anxiety\", \"n-distress\", \"n-sadness\"]\n",
    "    neutral = [\"u-belief\", \"u-fact\"]\n",
    "\n",
    "    if expression in positive:\n",
    "        return 0.25\n",
    "    elif expression in negative:\n",
    "        return -0.25\n",
    "    elif expression in neutral or expression == \"\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# 요약 비율 점수\n",
    "def score_summary_ratio(summary_wc, answer_wc):\n",
    "    if answer_wc == 0:\n",
    "        return 0\n",
    "    ratio = summary_wc / answer_wc\n",
    "    if ratio < 0.1 or ratio > 0.5:\n",
    "        return 0\n",
    "    elif 0.2 <= ratio <= 0.35:\n",
    "        return 1\n",
    "    elif 0.1 <= ratio < 0.2:\n",
    "        return round((1 * (ratio - 0.1) / 0.1), 2)\n",
    "    elif 0.35 < ratio <= 0.5:\n",
    "        return round((1 * (0.5 - ratio) / 0.15), 2)\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c83aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_file_paths(directory_paths):\n",
    "    \"\"\"모든 JSON 파일 경로를 재귀적으로 찾습니다.\"\"\"\n",
    "    file_paths = []\n",
    "    for path in directory_paths:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"경로가 존재하지 않습니다: {path}\")\n",
    "            continue\n",
    "        for root, _, files in os.walk(path):\n",
    "            for file in files:\n",
    "                if file.endswith('.json'):\n",
    "                    file_paths.append(os.path.join(root, file))\n",
    "    return file_paths\n",
    "\n",
    "def preprocess():\n",
    "    \"\"\"전체 전처리 과정을 실행하고 결과를 파일로 저장합니다.\"\"\"\n",
    "    print(\"면접 텍스트 데이터 전처리를 시작합니다.\")\n",
    "    \n",
    "    # 1. 데이터 로딩\n",
    "    all_json_files = get_all_file_paths([TRAINING_DATA_PATH, VALIDATION_DATA_PATH])\n",
    "    if not all_json_files:\n",
    "        print(\"오류: 지정된 경로에서 JSON 파일을 찾을 수 없습니다.\")\n",
    "        return\n",
    "\n",
    "    print(f\"총 {len(all_json_files)}개의 파일을 발견했습니다. 전처리를 진행합니다...\")\n",
    "    \n",
    "    processed_data = []\n",
    "    \n",
    "    for file_path in tqdm(all_json_files, desc=\"전처리 진행 중\"):\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                try:\n",
    "                    data = json.load(f)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"JSON 디코딩 오류: {file_path}: {e}\")\n",
    "                    continue\n",
    "                # 2. 원본 텍스트 추출\n",
    "                raw_question = data.get('dataSet', {}).get('question', {}).get('raw', {}).get('text', \"\")\n",
    "                raw_answer = data.get('dataSet', {}).get('answer', {}).get('raw', {}).get('text', \"\")\n",
    "                raw_answer_count = data.get('dataSet', {}).get('answer', {}).get('raw', {}).get('wordCount', \"\")\n",
    "                raw_answer_summary_count = data.get('dataSet', {}).get('answer', {}).get('summary', {}).get('wordCount', \"\")\n",
    "                raw_expression = data.get('dataSet', {}).get('answer', {}).get('intent', [])[0].get('expression', \"\")\n",
    "                # 3. 전처리 적용\n",
    "                clean_question = preprocess_text(raw_question)\n",
    "                clean_answer = preprocess_text(raw_answer)\n",
    "                \n",
    "                # 4. 유효성 검사 (Null, 빈 문자열, 최소 길이)\n",
    "                if not clean_question or not clean_answer:\n",
    "                    continue\n",
    "                if len(clean_question) < MIN_SENTENCE_LENGTH or len(clean_answer) < MIN_SENTENCE_LENGTH:\n",
    "                    continue\n",
    "                # 5. 최종 데이터 구조화\n",
    "                file_id = os.path.basename(file_path).split('.')[0]\n",
    "                processed_data.append({\n",
    "                    \"id\": file_id,\n",
    "                    \"question\": clean_question,\n",
    "                    \"answer\": clean_answer,\n",
    "                    \"answer_word_count\": raw_answer_count,\n",
    "                    \"answer_summary_word_count\": raw_answer_summary_count,\n",
    "                    \"expression\": raw_expression,\n",
    "                })\n",
    "        except FileNotFoundError:\n",
    "            print(f\"파일을 찾을 수 없습니다: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"알 수 없는 오류 발생 {file_path}: {e}\")\n",
    "\n",
    "    print(f\"전처리 완료. 총 {len(processed_data)}개의 유효한 데이터가 처리되었습니다.\")\n",
    "    return processed_data\n",
    "\n",
    "def add_similarity_scores_to_json(data, model):\n",
    "    # data = json.load(data)\n",
    "    print(\"유사도 점수 계산을 시작합니다...\")\n",
    "    updated_data = []\n",
    "    for item in tqdm(data, desc=\"유사도 점수 계산 중\", ncols=100):\n",
    "        question = item[\"question\"]\n",
    "        answer = item[\"answer\"]\n",
    "        score = compute_similarity(question, answer, model)\n",
    "\n",
    "        # 점수 추가\n",
    "        item[\"similarity_score\"] = round(score, 4)\n",
    "        updated_data.append(item)\n",
    "\n",
    "\n",
    "    max_score = max(item[\"similarity_score\"] for item in updated_data)\n",
    "    min_score = min(item[\"similarity_score\"] for item in updated_data)\n",
    "\n",
    "    for item in tqdm(updated_data, desc=\"유사도 점수 정규화 중\", ncols=100):\n",
    "        item[\"normalized_similarity_score\"] = round(normalize_score(item[\"similarity_score\"], min_score, max_score), 4)\n",
    "    \n",
    "\n",
    "    del item[\"similarity_score\"]\n",
    "\n",
    "    print(\"유사도 점수 계산 완료.\")\n",
    "    return updated_data\n",
    "\n",
    "def scoring(data):\n",
    "    print(\"점수 계산을 시작합니다...\")\n",
    "    for item in tqdm(data, desc=\"최종 점수 계산 중\", ncols=100):\n",
    "        item['score'] = 0\n",
    "        item['score'] += get_emotion_score(item['expression'])\n",
    "        item['score'] += score_summary_ratio(item['answer_summary_word_count'], item['answer_word_count'])\n",
    "        item['score'] += item['normalized_similarity_score']\n",
    "        item['score'] = round(item['score'] * 100 / 3, 4)\n",
    "\n",
    "    print(\"점수 계산 완료.\")\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d159e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    temp1 = preprocess()\n",
    "    temp2 = add_similarity_scores_to_json(temp1, model)\n",
    "    temp3 = scoring(temp2)\n",
    "    save_json(temp3, OUTPUT_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80c42741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "면접 텍스트 데이터 전처리를 시작합니다.\n",
      "총 6572개의 파일을 발견했습니다. 전처리를 진행합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "전처리 진행 중: 100%|██████████| 6572/6572 [00:03<00:00, 2091.73it/s]\n",
      "전처리 진행 중: 100%|██████████| 6572/6572 [00:03<00:00, 2091.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 완료. 총 6572개의 유효한 데이터가 처리되었습니다.\n",
      "유사도 점수 계산을 시작합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "유사도 점수 계산 중: 100%|██████████████████████████████████████| 6572/6572 [36:07<00:00,  3.03it/s]\n",
      "유사도 점수 계산 중: 100%|██████████████████████████████████████| 6572/6572 [36:07<00:00,  3.03it/s]\n",
      "유사도 점수 정규화 중: 100%|███████████████████████████████| 6572/6572 [00:00<00:00, 1328048.08it/s]\n",
      "유사도 점수 정규화 중: 100%|███████████████████████████████| 6572/6572 [00:00<00:00, 1328048.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도 점수 계산 완료.\n",
      "점수 계산을 시작합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "최종 점수 계산 중: 100%|████████████████████████████████████| 6572/6572 [00:00<00:00, 306294.42it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "점수 계산 완료.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c992640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handspell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
