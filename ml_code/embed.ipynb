{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d74adf8",
   "metadata": {},
   "source": [
    "## ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ëª¨ë¸ ì„ ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff0ce14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\final_git\\SKN12-FINAL-5TEAM\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# ë°ì´í„° ê²½ë¡œ (os.path.join ì‚¬ìš©, ì ˆëŒ€ ê²½ë¡œ)\n",
    "BASE_DIR = os.path.dirname(os.getcwd())  # ml_code í´ë”ì˜ ìƒìœ„ í´ë”ë¡œ ì´ë™\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data', 'ML')\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "print(BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d24b38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\final_git\\SKN12-FINAL-5TEAM\n",
      "c:\\final_git\\SKN12-FINAL-5TEAM\\data\\ML\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name BM-K/KoSimCSE-roberta. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BiEncoder loaded on: cpu, max_seq_length: 512\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ (os.path.join ì‚¬ìš©, ì ˆëŒ€ ê²½ë¡œ)\n",
    "BASE_DIR = os.path.dirname(os.getcwd())  # ml_code í´ë”ì˜ ìƒìœ„ í´ë”ë¡œ ì´ë™\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data', 'ML')\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "print(BASE_DIR)\n",
    "print(DATA_DIR)\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ í™•ì¸ (cudaê°€ ìˆìœ¼ë©´ GPU ì‚¬ìš©)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# BiEncoder ëª¨ë¸ ë¡œë”©\n",
    "bi_model = SentenceTransformer(\"BM-K/KoSimCSE-roberta\")\n",
    "bi_model.to(device)\n",
    "\n",
    "# (ì„ íƒ) ìµœëŒ€ ë¬¸ì¥ ê¸¸ì´ ì¡°ì •í•˜ê³  ì‹¶ìœ¼ë©´ ì•„ë˜ì²˜ëŸ¼ ì„¤ì • ê°€ëŠ¥\n",
    "bi_model.max_seq_length = 512  # ê¸°ë³¸ì€ 384ì¸ë° í•„ìš” ì‹œ ëŠ˜ë¦¬ê¸° ê°€ëŠ¥\n",
    "\n",
    "print(f\"âœ… BiEncoder loaded on: {device}, max_seq_length: {bi_model.max_seq_length}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35a6453",
   "metadata": {},
   "source": [
    "## json ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a9ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ë°ì´í„° ë¶„í•  ë¹„ìœ¨ ì„¤ì •\n",
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "\n",
    "def split_data(data, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    \"\"\"ë°ì´í„°ë¥¼ train, val, testë¡œ ë¶„í• í•©ë‹ˆë‹¤.\"\"\"\n",
    "    random.shuffle(data)\n",
    "    total_size = len(data)\n",
    "    \n",
    "    train_size = int(total_size * train_ratio)\n",
    "    val_size = int(total_size * val_ratio)\n",
    "    \n",
    "    train_data = data[:train_size]\n",
    "    val_data = data[train_size:train_size + val_size]\n",
    "    test_data = data[train_size + val_size:]\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def load_qa_data(data, split_name=\"\"):\n",
    "\n",
    "    qas = []\n",
    "    scores = []\n",
    "    for d in tqdm(data, desc=f\"ğŸ“¦ Loading {split_name}\", ncols=100):\n",
    "        qas.append((d['question'], d['answer']))\n",
    "        scores.append(d['score'])\n",
    "    print(f\"âœ… Loaded {len(qas)} Q&A pairs from {split_name} data.\")\n",
    "\n",
    "    SAVE_FILE_PATH = os.path.join(DATA_DIR, f\"{split_name}_data.json\")\n",
    "    with open(SAVE_FILE_PATH, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    return qas, scores\n",
    "\n",
    "def embed_qas(qas, model, split_name=\"\"):\n",
    "    print(f\"ğŸš€ Embedding {split_name}...\")\n",
    "\n",
    "    questions = [q for q, _ in qas]\n",
    "    answers = [a for _, a in qas]\n",
    "\n",
    "    # ê° ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©\n",
    "    q_vecs = model.encode(\n",
    "        questions,\n",
    "        convert_to_numpy=True,\n",
    "        batch_size=32,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    a_vecs = model.encode(\n",
    "        answers,\n",
    "        convert_to_numpy=True,\n",
    "        batch_size=32,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    # ë²¡í„° ì´ì–´ë¶™ì´ê¸° (concat)\n",
    "    features = [list(q) + list(a) for q, a in tqdm(zip(q_vecs, a_vecs), total=len(qas), desc=f\"ğŸ”— Merging {split_name}\", ncols=100)]\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17e923f",
   "metadata": {},
   "source": [
    "## questionê³¼ answer ê°ê° ì„ë² ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07d833af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data split complete - Train: 5257, Val: 657, Test: 658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Loading train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5257/5257 [00:00<?, ?it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 5257 Q&A pairs from train data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Loading val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 657/657 [00:00<?, ?it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 657 Q&A pairs from val data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Loading test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 658/658 [00:00<00:00, 89324.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 658 Q&A pairs from test data.\n",
      "ğŸš€ Embedding train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 165/165 [02:08<00:00,  1.28it/s]\n",
      "\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 165/165 [23:45<00:00,  8.64s/it]\n",
      "ğŸ”— Merging train:   0%|                                                    | 0/5257 [00:00<?, ?it/s]\n",
      "ğŸ”— Merging train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5257/5257 [00:00<00:00, 10059.59it/s]\n",
      "ğŸ”— Merging train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5257/5257 [00:00<00:00, 10059.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Embedding val...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:17<00:00,  1.19it/s]\n",
      "Batches:   0%|          | 0/21 [00:00<?, ?it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:25<00:00,  6.92s/it]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:25<00:00,  6.92s/it]                    | 0/657 [00:00<?, ?it/s]\n",
      "ğŸ”— Merging val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 657/657 [00:00<00:00, 10558.04it/s]\n",
      "ğŸ”— Merging val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 657/657 [00:00<00:00, 10558.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Embedding test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:18<00:00,  1.14it/s]\n",
      "Batches:   0%|          | 0/21 [00:00<?, ?it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:25<00:00,  6.93s/it]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [02:25<00:00,  6.93s/it]\n",
      "ğŸ”— Merging test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 658/658 [00:00<00:00, 5393.76it/s]\n",
      "ğŸ”— Merging test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 658/658 [00:00<00:00, 5393.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocessed_data.json ë¡œë“œ\n",
    "with open(INPUT_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "    processed_data = json.load(f)\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "train_data, val_data, test_data = split_data(processed_data, TRAIN_RATIO, VAL_RATIO, TEST_RATIO)\n",
    "\n",
    "print(f\"âœ… Data split complete - Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")\n",
    "\n",
    "# í˜¸ì¶œ ì‹œ split ì´ë¦„ ëª…ì‹œ\n",
    "train_qa, y_train = load_qa_data(train_data, split_name=\"train\")\n",
    "val_qa, y_val = load_qa_data(val_data, split_name=\"val\")\n",
    "test_qa, y_test = load_qa_data(test_data, split_name=\"test\")\n",
    "\n",
    "X_train = embed_qas(train_qa, bi_model, split_name=\"train\")\n",
    "X_val = embed_qas(val_qa, bi_model, split_name=\"val\")\n",
    "X_test = embed_qas(test_qa, bi_model, split_name=\"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fefa728",
   "metadata": {},
   "source": [
    "## arrayë¡œ ë³€í™˜ í›„ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "640cdd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# numpy arrayë¡œ ë³€í™˜ \n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# ë°ì´í„° ì €ì¥\n",
    "np.savez(os.path.join(DATA_DIR, \"train_set.npz\"), X=X_train, y=y_train)\n",
    "np.savez(os.path.join(DATA_DIR, \"val_set.npz\"), X=X_val, y=y_val)\n",
    "np.savez(os.path.join(DATA_DIR, \"test_set.npz\"), X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbed6ec",
   "metadata": {},
   "source": [
    "## ì €ì¥í•œ array ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fb2c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load(os.path.join(DATA_DIR, \"train_set.npz\"))\n",
    "X_train = train[\"X\"]\n",
    "y_train = train[\"y\"]\n",
    "\n",
    "val = np.load(os.path.join(DATA_DIR, \"val_set.npz\"))\n",
    "X_val = val[\"X\"]\n",
    "y_val = val[\"y\"]\n",
    "\n",
    "test = np.load(os.path.join(DATA_DIR, \"test_set.npz\"))\n",
    "X_test = test[\"X\"]\n",
    "y_test = test[\"y\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handspell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
